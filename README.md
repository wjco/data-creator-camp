# data-creator-camp
공모전 <2023 데이터 크리에이터 캠프>에 5인 팀 '안녕하데요'로 참여한 기록

<br>

## 0. 전반적인 후기
이미지 분류 딥러닝 모델을 생성, 학습, 튜닝하는 프로젝트를 진행했다. 딥러닝 프레임워크를 직접적으로 심도 있게 다루는 경험은 이번이 처음이었다. 낯선 게 많았다. 그만큼 다양한 시행착오를 겪었다. 물론 그렇게 부딪히면서 성장해 나갈 수 있었기에 개인적으로 만족스러운 프로젝트였다. 무엇보다도 딥러닝 학습의 기본적인 flow를 처음으로 경험할 수 있었다는 점에서 가장 큰 의의를 찾을 수 있을 것 같다.

<br>

## 1. ResNet18 모델을 최초로 생성한 경험

### MISSION 1-1
42개 클래스의 음식 이미지들을 각 클래스별 1장씩 시각화하는 과정을 수행했다.

### MISSION 1-2
ResNet18을 이용해서 이미지 분류 모델을 생성했다. 프레임워크는 Pytorch를 사용했다. 데이터를 로딩하고, 모델 아키텍처를 생성하고, Loss Function, Optimizer, Scheduler를 정의하고, 학습을 진행시켰다.

이 단계에서 가장 고민이 되었던 건 **리소스 투입의 문제**였다. 우선 시간적으로, 한 epoch 당 최소 6분이 소요되는 작업이라 밤에 모델 돌려놓고 자는 일이 빈번했다. 또한 컴퓨터 자원이 팽팽 돌아가야만 했기에 중간에 세션이 종료되는 등의 예기치 못한 상황들이 빈번히 발생했다. 이를 컨트롤하기 위해 모델의 상태와 가중치를 체크포인트로, 그 외 다양한 변수들을 피클로 저장하여 다루는 관성을 익혔다.

<br>

## 2. 모델 성능 향상에 대한 고민

### MISSION 2-1
앞서 언급했던 바와 같이 적게는 수 시간, 많게는 수십 시간에 걸친 학습 과정이 내게는 너무나도 낯설었다. 그래서 최초의 관심사는 어떻게 하면 **epoch을 줄일 수 있을까** 하는 것이었다. 어떤 지점에서 성능의 증가율이 둔해지는지, 어떤 지점에서 validation accuracy가 튀는 경향이 안정화되는지, 또 어떤 지점에서 성능 지표가 수렴하는지 등을 체크했다. 이 과정이 추후 단계들의 진행에 큰 도움을 주었다.

### MISSION 2-2
딥러닝 역시 당연하게도 튜닝을 통해 성능을 개선해야 할 것이라고 예상은 하고 있었다. 내가 지금껏 머신러닝 모델을 다루면서 경험했던 스케일이 아니었을 뿐.

데이터 증강, LR Scheduler 등 다양한 가짓수들을 직접 돌려보면서 모델의 성능을 측정하는 과정이 **굉장히 오랜 시간을 잡아먹었다.** 그래서 성능과 시간의 교묘한 타협점인 20 epoch을 기준으로 잡고 매 시행에 들어갔다. 그렇게 했음에도 상당한 리소스를 투입해야만 했다.

**데이터 증강 방식에 대한 고민**도 있었다. 예컨대 전체 데이터를 증강하는 방법과, 일부 성능 낮은 클래스만을 증강하는 방법 중 어느 쪽이 더 효과적일까 하는 것들. 최초에는, 모델이 잘 구분하지 못하는 이미지의 특징을 집중적으로 학습시키면 약점을 보완하여 최종적으로 더 나은 퍼포먼스를 보일 거라고 생각했다. 하지만 내가 직접 확인해 본 결과는 달랐다. 특정한 클래스에 치중하지 않고 고르게 증강했을 때 훨씬 좋은 성능을 보였다. 아무래도 '음식'이라는 큰 범주 안에서 구성된 데이터인 만큼 균형을 무너뜨리지 않고 고르게 학습시키는 게 유리한 방향이었던 모양이다.

### MISSION 2-3
앞서 성능을 강화할 방법을 모색했는데, 그 결과물로 최종 모델 학습을 도출해 냈다. 각 파라미터와 방법론 중 최적을 선정했다. 모델을 50 epoch까지 학습시키면서, 그 중 성능이 가장 우월했던 하나의 모델을 선정하는 것으로 전략을 세웠다. 튜닝의 결과로, 기존에 비해 validation accuracy가 **10%p 넘게 상승**한 모델을 얻을 수 있었다. 많은 리소스를 투입한 과정이었기에 더욱 뿌듯했다.

<br>

## 3. 시간의 압박, 그리고 성취

### MISSION 3-1
다른 데이터셋으로 학습한 모델을 그와 유사한 데이터셋으로 옮겨 적용할 수 있다는 게 꽤나 흥미를 자극했다. 실제로 모델 학습에 돌입하기 앞서 파인튜닝에 대한 서칭을 해봤다. 데이터셋의 크기와 유사도에 따라 4가지 전략을 사용할 수 있다고 했다. 그 중 내가 가장 기대했던 전략은, **모델의 일부분(레이어의 뒷부분)과 Classifier를 학습**시키는 것이었다. 우리 데이터는 크기도 충분히 크고 유사도도 높은 편이어서 이 방향성이 가장 유리하겠다고 판단했다. 다만 Linear Probing 같은 기법들도 내가 선택지 중 하나로 고려해 봄직한 것이었다.

우리는 시간에 쫓기는 상태였기 때문에 각자 파인튜닝 방법론을 하나씩 도맡아 진행했다. 이 단계에서도 역시 매 epoch마다 성능을 트래킹하면서 가장 우월한 가중치를 저장하도록 했다.

### MISSION 3-2
예상했던 것 이상의 압도적인 성능 점수를 얻었다. validation accuracy가 **무려 95%를 상회**했다. 내 예상이 보기 좋게 들어맞았던 순간이라 꽤나 짜릿했다!
